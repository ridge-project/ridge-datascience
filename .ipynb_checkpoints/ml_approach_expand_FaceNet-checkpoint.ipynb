{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from numpy import genfromtxt\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print(\"Inside triplet loss\")\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    print(anchor)\n",
    "    print(positive)\n",
    "    print(negative)\n",
    "    ### START CODE HERE ### (Ëœ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    print(\"Entering the function\")\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceRecoModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception model used for FaceNet\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # First Block\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Zero-Padding + MAXPOOL\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = MaxPooling2D((3, 3), strides = 2)(X)\n",
    "    \n",
    "    # Second Block\n",
    "    X = Conv2D(64, (1, 1), strides = (1, 1), name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Zero-Padding + MAXPOOL\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Zero-Padding + MAXPOOL\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    \n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n",
    "    \n",
    "    X = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, name='dense_layer')(X)\n",
    "    \n",
    "    # L2 normalization\n",
    "    X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
    "    \n",
    "             \n",
    "    # Create model instance\n",
    "    model = Model(inputs = X_input, outputs = X, name='FaceRecoModel')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FLOATX = 'float32'\n",
    "def variable(value, dtype=_FLOATX, name=None):\n",
    "    v = tf.Variable(np.asarray(value, dtype=dtype), name=name)\n",
    "    _get_session().run(v.initializer)\n",
    "    return v\n",
    "\n",
    "def shape(x):\n",
    "    return x.get_shape()\n",
    "\n",
    "def square(x):\n",
    "    return tf.square(x)\n",
    "\n",
    "def zeros(shape, dtype=_FLOATX, name=None):\n",
    "    return variable(np.zeros(shape), dtype, name)\n",
    "\n",
    "def concatenate(tensors, axis=-1):\n",
    "    if axis < 0:\n",
    "        axis = axis % len(tensors[0].get_shape())\n",
    "    return tf.concat(axis, tensors)\n",
    "\n",
    "def LRN2D(x):\n",
    "    return tf.nn.lrn(x, alpha=1e-4, beta=0.75)\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              layer=None,\n",
    "              cv1_out=None,\n",
    "              cv1_filter=(1, 1),\n",
    "              cv1_strides=(1, 1),\n",
    "              cv2_out=None,\n",
    "              cv2_filter=(3, 3),\n",
    "              cv2_strides=(1, 1),\n",
    "              padding=None):\n",
    "    num = '' if cv2_out == None else '1'\n",
    "    tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, data_format='channels_first', name=layer+'_conv'+num)(x)\n",
    "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
    "    tensor = Activation('relu')(tensor)\n",
    "    if padding == None:\n",
    "        return tensor\n",
    "    tensor = ZeroPadding2D(padding=padding, data_format='channels_first')(tensor)\n",
    "    if cv2_out == None:\n",
    "        return tensor\n",
    "    tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, data_format='channels_first', name=layer+'_conv'+'2')(tensor)\n",
    "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
    "    tensor = Activation('relu')(tensor)\n",
    "    return tensor\n",
    "\n",
    "WEIGHTS_mod = [\n",
    "  'conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3'\n",
    "]\n",
    "conv_shape = {\n",
    "  'conv1': [64, 3, 7, 7],\n",
    "  'conv2': [64, 64, 1, 1],\n",
    "  'conv3': [192, 64, 3, 3]\n",
    "}\n",
    "\n",
    "def load_weights_from_FaceNet(FRmodel):\n",
    "    # Load weights from csv files (which was exported from Openface torch model)\n",
    "    weights = WEIGHTS_mod\n",
    "    weights_dict = load_weights()\n",
    "\n",
    "    # Set layer weights of the model\n",
    "    for name in weights:\n",
    "        if FRmodel.get_layer(name) != None:\n",
    "            FRmodel.get_layer(name).set_weights(weights_dict[name])\n",
    "        elif model.get_layer(name) != None:\n",
    "            model.get_layer(name).set_weights(weights_dict[name])\n",
    "\n",
    "def load_weights():\n",
    "    # Set weights path\n",
    "    dirPath = './weights'\n",
    "    fileNames = filter(lambda f: not f.startswith('.'), os.listdir(dirPath))\n",
    "    paths = {}\n",
    "    weights_dict = {}\n",
    "\n",
    "    for n in fileNames:\n",
    "        paths[n.replace('.csv', '')] = dirPath + '/' + n\n",
    "\n",
    "    for name in WEIGHTS_mod:\n",
    "        if 'conv' in name:\n",
    "            conv_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
    "            conv_w = np.reshape(conv_w, conv_shape[name])\n",
    "            conv_w = np.transpose(conv_w, (2, 3, 1, 0))\n",
    "            conv_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [conv_w, conv_b]     \n",
    "        elif 'bn' in name:\n",
    "            bn_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
    "            bn_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
    "            bn_m = genfromtxt(paths[name + '_m'], delimiter=',', dtype=None)\n",
    "            bn_v = genfromtxt(paths[name + '_v'], delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [bn_w, bn_b, bn_m, bn_v]\n",
    "        elif 'dense' in name:\n",
    "            dense_w = genfromtxt(dirPath+'/dense_w.csv', delimiter=',', dtype=None)\n",
    "            dense_w = np.reshape(dense_w, (128, 736))\n",
    "            dense_w = np.transpose(dense_w, (1, 0))\n",
    "            dense_b = genfromtxt(dirPath+'/dense_b.csv', delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [dense_w, dense_b]\n",
    "\n",
    "    return weights_dict\n",
    "\n",
    "def img_to_encoding(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    flat_input=embedding.flatten()\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside triplet loss\n",
      "Tensor(\"loss/lambda_1_loss/strided_slice:0\", shape=(128,), dtype=float32)\n",
      "Tensor(\"loss/lambda_1_loss/strided_slice_1:0\", shape=(128,), dtype=float32)\n",
      "Tensor(\"loss/lambda_1_loss/strided_slice_2:0\", shape=(128,), dtype=float32)\n",
      "Entering the function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FRmodel = faceRecoModel(input_shape=(3, 350, 350))\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def show_images(image_path_original,image_path_check):\n",
    "    \n",
    "    imageA=mpimg.imread(image_path_original)\n",
    "    imageB=mpimg.imread(image_path_check)\n",
    "    fig = plt.figure(\"Comparison\")\n",
    " \n",
    "    # show first image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    # show the second image\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    # show the images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path_original, image_path_check, model): \n",
    "    \n",
    "    encoding_original = img_to_encoding(image_path_original,model)\n",
    "    encoding_check = img_to_encoding(image_path_check,model)\n",
    "    \n",
    "    dist = np.linalg.norm(encoding_original-encoding_check)\n",
    "    dist = dist/256\n",
    "    # setup the figure\n",
    "    \n",
    "    show_images(image_path_original,image_path_check)\n",
    "    print (\"Distance is \" , dist)\n",
    "    if dist < 1:\n",
    "        print(\"It's similar\")          \n",
    "    else:\n",
    "        print(\"It's not similar\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def verify_ml_approach(image_path_original,image_path_check):\n",
    "    verify(image_path_original, image_path_check, FRmodel)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    dataset = np.genfromtxt(\"data.csv\", dtype=\"U\" ,delimiter=\",\" )\n",
    "    X = dataset[:,0:2]\n",
    "    Y = dataset[:,2]\n",
    "    Y= [int(i) for i in Y]\n",
    "    m=len(Y)\n",
    "    return X,Y,m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getimagePath(name):\n",
    "    return('images/'+str(name)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimpleModel():\n",
    "    inputs=Input(shape=(128,))\n",
    "    # a layer instance is callable on a tensor, and returns a tensor\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "  #  x = Dense(64, activation='relu')(x)\n",
    "    predictions = Dense(11, activation='softmax')(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and three Dense layers\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeqModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(X,Y,m,classes=11):\n",
    "    dat=np.zeros((1,128))\n",
    "    data=np.zeros((m,128))\n",
    "    labels=np.zeros((m,classes))\n",
    "    row=0\n",
    "    for [ori,chk] in X:\n",
    "        ori_encoding=img_to_encoding(getimagePath(ori), FRmodel)\n",
    "        chk_encoding=img_to_encoding(getimagePath(chk), FRmodel)\n",
    "        dat=(ori_encoding-chk_encoding)\n",
    "        data[row,:]=dat\n",
    "        labels[row,Y[row]]=1\n",
    "        row=row+1  \n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2nd_model():\n",
    "    X,Y,m=load_train_data()\n",
    "    data,labels=prepare_train_data(X,Y,m)\n",
    "\n",
    "    Smodel=getSimpleModel()\n",
    "    Smodel.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    Smodel.fit(data,labels,epochs=500 )  # starts training\n",
    "    score = Smodel.evaluate(data,labels)\n",
    "    return Smodel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 2s 66ms/step - loss: 2.3847 - acc: 0.0938\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 315us/step - loss: 2.3562 - acc: 0.3750\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 373us/step - loss: 2.3328 - acc: 0.4062\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 221us/step - loss: 2.3145 - acc: 0.5000\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 455us/step - loss: 2.2983 - acc: 0.5000\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 563us/step - loss: 2.2831 - acc: 0.5000\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.2690 - acc: 0.5000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.2555 - acc: 0.4688\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 242us/step - loss: 2.2423 - acc: 0.4688\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 346us/step - loss: 2.2292 - acc: 0.4688\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 414us/step - loss: 2.2162 - acc: 0.4375\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2033 - acc: 0.4375\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 387us/step - loss: 2.1906 - acc: 0.4375\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 593us/step - loss: 2.1780 - acc: 0.4375\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 380us/step - loss: 2.1654 - acc: 0.4375\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 346us/step - loss: 2.1530 - acc: 0.4375\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 241us/step - loss: 2.1407 - acc: 0.4375\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 289us/step - loss: 2.1283 - acc: 0.4375\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1159 - acc: 0.4375\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.1032 - acc: 0.4375\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 463us/step - loss: 2.0907 - acc: 0.4375\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 496us/step - loss: 2.0780 - acc: 0.4375\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 746us/step - loss: 2.0655 - acc: 0.4375\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 302us/step - loss: 2.0529 - acc: 0.4375\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.0403 - acc: 0.4375\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 179us/step - loss: 2.0275 - acc: 0.4375\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.0146 - acc: 0.4375\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 2.0016 - acc: 0.4375\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 220us/step - loss: 1.9887 - acc: 0.4375\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 1.9758 - acc: 0.4375\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9630 - acc: 0.4375\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 161us/step - loss: 1.9501 - acc: 0.4375\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 1.9370 - acc: 0.4375\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9241 - acc: 0.4375\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 619us/step - loss: 1.9113 - acc: 0.4375\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 451us/step - loss: 1.8982 - acc: 0.4375\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 167us/step - loss: 1.8853 - acc: 0.4375\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 304us/step - loss: 1.8722 - acc: 0.4375\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 359us/step - loss: 1.8589 - acc: 0.4375\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 391us/step - loss: 1.8458 - acc: 0.4375\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 224us/step - loss: 1.8329 - acc: 0.4375\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.8198 - acc: 0.4375\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 411us/step - loss: 1.8068 - acc: 0.4375\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 248us/step - loss: 1.7938 - acc: 0.4375\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 197us/step - loss: 1.7808 - acc: 0.4375\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 359us/step - loss: 1.7677 - acc: 0.4375\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 1.7547 - acc: 0.4375\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.7417 - acc: 0.4375\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 300us/step - loss: 1.7287 - acc: 0.4375\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 458us/step - loss: 1.7160 - acc: 0.4375\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 183us/step - loss: 1.7031 - acc: 0.4375\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 299us/step - loss: 1.6903 - acc: 0.4375\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 637us/step - loss: 1.6777 - acc: 0.4375\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6651 - acc: 0.4375\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 448us/step - loss: 1.6527 - acc: 0.4375\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 485us/step - loss: 1.6401 - acc: 0.4375\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 386us/step - loss: 1.6279 - acc: 0.4375\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 871us/step - loss: 1.6156 - acc: 0.4375\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 209us/step - loss: 1.6034 - acc: 0.4375\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.5913 - acc: 0.4375\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 243us/step - loss: 1.5794 - acc: 0.4375\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 442us/step - loss: 1.5675 - acc: 0.4375\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 406us/step - loss: 1.5557 - acc: 0.4375\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 222us/step - loss: 1.5440 - acc: 0.4375\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 372us/step - loss: 1.5324 - acc: 0.4375\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.5210 - acc: 0.4375\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 487us/step - loss: 1.5097 - acc: 0.4375\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 630us/step - loss: 1.4984 - acc: 0.4375\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 458us/step - loss: 1.4871 - acc: 0.4375\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 353us/step - loss: 1.4761 - acc: 0.4375\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4652 - acc: 0.4375\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 256us/step - loss: 1.4542 - acc: 0.4375\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 243us/step - loss: 1.4436 - acc: 0.4375\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 207us/step - loss: 1.4330 - acc: 0.4375\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 205us/step - loss: 1.4223 - acc: 0.4375\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 273us/step - loss: 1.4120 - acc: 0.4375\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4016 - acc: 0.4375\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 412us/step - loss: 1.3914 - acc: 0.4375\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 229us/step - loss: 1.3813 - acc: 0.4375\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 396us/step - loss: 1.3715 - acc: 0.4375\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 190us/step - loss: 1.3614 - acc: 0.4375\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 415us/step - loss: 1.3516 - acc: 0.4375\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3419 - acc: 0.4375\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 1.3324 - acc: 0.4375\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 1.3228 - acc: 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 66us/step - loss: 1.3135 - acc: 0.4375\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 1.3040 - acc: 0.4375\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 1.2948 - acc: 0.4375\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 1.2856 - acc: 0.4375\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 1.2763 - acc: 0.4375\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 1.2673 - acc: 0.4375\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 1.2582 - acc: 0.4375\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 67us/step - loss: 1.2495 - acc: 0.4375\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 1.2406 - acc: 0.4375\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 1.2318 - acc: 0.4375\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 55us/step - loss: 1.2231 - acc: 0.4688\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 1.2146 - acc: 0.4688\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 142us/step - loss: 1.2061 - acc: 0.4688\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1975 - acc: 0.4688\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 370us/step - loss: 1.1892 - acc: 0.4688\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 280us/step - loss: 1.1808 - acc: 0.7812\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 404us/step - loss: 1.1725 - acc: 0.7812\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 161us/step - loss: 1.1643 - acc: 0.7812\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 618us/step - loss: 1.1557 - acc: 0.7812\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 505us/step - loss: 1.1474 - acc: 0.7812\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 424us/step - loss: 1.1392 - acc: 0.7812\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1310 - acc: 0.7812\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 1.1228 - acc: 0.7812\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 72us/step - loss: 1.1148 - acc: 0.7812\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 1.1067 - acc: 0.7812\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 1.0988 - acc: 0.7812\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 1.0909 - acc: 0.7812\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 1.0830 - acc: 0.7812\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 151us/step - loss: 1.0752 - acc: 0.7812\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 1.0674 - acc: 0.7812\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 1.0596 - acc: 0.7812\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 68us/step - loss: 1.0519 - acc: 0.7812\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 1.0440 - acc: 0.7812\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 1.0363 - acc: 0.7812\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 1.0286 - acc: 0.7812\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 1.0210 - acc: 0.7812\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 145us/step - loss: 1.0134 - acc: 0.7812\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 1.0057 - acc: 0.7812\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 0.9983 - acc: 0.7812\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.9906 - acc: 0.7812\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.9831 - acc: 0.7812\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 70us/step - loss: 0.9757 - acc: 0.7812\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.9682 - acc: 0.7812\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.9608 - acc: 0.7812\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 70us/step - loss: 0.9534 - acc: 0.7812\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 0.9461 - acc: 0.7812\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 0.9387 - acc: 0.7812\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 0.9314 - acc: 0.7812\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 0.9241 - acc: 0.7812\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 0.9169 - acc: 0.7812\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 524us/step - loss: 0.9095 - acc: 0.7812\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.9024 - acc: 0.7812\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.8953 - acc: 0.7812\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 59us/step - loss: 0.8881 - acc: 0.7812\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 0.8810 - acc: 0.7812\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.8738 - acc: 0.7812\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.8666 - acc: 0.7812\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.8596 - acc: 0.7812\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.8526 - acc: 0.7812\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.8455 - acc: 0.7812\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.8385 - acc: 0.7812\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 0.8316 - acc: 0.7812\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 0.8247 - acc: 0.7812\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 308us/step - loss: 0.8177 - acc: 0.7812\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.8109 - acc: 0.7812\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 0.8039 - acc: 0.7812\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 0.7970 - acc: 0.7812\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.7903 - acc: 0.7812\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 0.7836 - acc: 0.7812\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 0.7768 - acc: 0.7812\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.7701 - acc: 0.7812\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 0.7634 - acc: 0.7812\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 0.7567 - acc: 0.7812\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 0.7501 - acc: 0.8125\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.7434 - acc: 0.8125\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 0.7369 - acc: 0.8125\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 611us/step - loss: 0.7305 - acc: 0.8125\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.7239 - acc: 0.8125\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.7173 - acc: 0.8125\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 0.7110 - acc: 0.8125\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.7045 - acc: 0.8125\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.6981 - acc: 0.8438\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 0.6918 - acc: 0.8438\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.6856 - acc: 0.8438\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 233us/step - loss: 0.6793 - acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.6730 - acc: 0.8438\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 0.6667 - acc: 0.8438\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 66us/step - loss: 0.6607 - acc: 0.8438\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.6545 - acc: 0.8750\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.6485 - acc: 0.8750\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 0.6423 - acc: 0.8750\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.6363 - acc: 0.9062\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.6303 - acc: 0.9062\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 494us/step - loss: 0.6244 - acc: 0.9062\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.6184 - acc: 0.9062\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 67us/step - loss: 0.6124 - acc: 0.9062\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 0.6066 - acc: 0.9062\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 0.6008 - acc: 0.9062\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.5949 - acc: 0.9062\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.5892 - acc: 0.9062\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 0.5834 - acc: 0.9062\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 0.5777 - acc: 0.9062\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 0.5721 - acc: 0.9062\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 58us/step - loss: 0.5664 - acc: 0.9062\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.5607 - acc: 0.9062\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.5553 - acc: 0.9062\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.5497 - acc: 0.9062\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 0.5442 - acc: 0.9062\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.5388 - acc: 0.9062\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 70us/step - loss: 0.5333 - acc: 0.9375\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 0.5280 - acc: 0.9375\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 0.5226 - acc: 0.9375\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 0.5173 - acc: 0.9375\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.5121 - acc: 0.9375\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.5069 - acc: 0.9375\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 0.5017 - acc: 0.9375\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.4966 - acc: 0.9688\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 66us/step - loss: 0.4915 - acc: 0.9688\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 0.4863 - acc: 0.9688\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.4814 - acc: 0.9688\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.4764 - acc: 0.9688\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 0.4714 - acc: 0.9688\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.4664 - acc: 0.9688\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 0.4616 - acc: 0.9688\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.4568 - acc: 0.9688\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.4520 - acc: 0.9688\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 45us/step - loss: 0.4472 - acc: 0.9688\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4426 - acc: 0.9688\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.4379 - acc: 0.9688\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 0.4333 - acc: 0.9688\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 0.4287 - acc: 0.9688\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 0.4242 - acc: 0.9688\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.4197 - acc: 0.9688\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 0.4153 - acc: 0.9688\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 0.4108 - acc: 0.9688\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.4065 - acc: 0.9688\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.4022 - acc: 0.9688\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 67us/step - loss: 0.3979 - acc: 0.9688\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.3937 - acc: 0.9688\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.3894 - acc: 0.9688\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 0.3852 - acc: 0.9688\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 53us/step - loss: 0.3811 - acc: 0.9688\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 442us/step - loss: 0.3770 - acc: 0.9688\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 0.3731 - acc: 0.9688\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.3689 - acc: 0.9688\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.3650 - acc: 0.9688\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.3611 - acc: 0.9688\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 258us/step - loss: 0.3571 - acc: 0.9688\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 227us/step - loss: 0.3533 - acc: 0.9688\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 212us/step - loss: 0.3495 - acc: 0.9688\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 216us/step - loss: 0.3457 - acc: 0.9688\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 0.3419 - acc: 0.9688\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 0.3382 - acc: 0.9688\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.3346 - acc: 0.9688\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 0.3310 - acc: 0.9688\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.3274 - acc: 0.9688\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 30us/step - loss: 0.3238 - acc: 0.9688\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.3204 - acc: 0.9688\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.3168 - acc: 0.9688\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.3134 - acc: 0.9688\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 38us/step - loss: 0.3100 - acc: 0.9688\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 256us/step - loss: 0.3065 - acc: 0.9688\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.3032 - acc: 0.9688\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 347us/step - loss: 0.3000 - acc: 0.9688\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2966 - acc: 0.9688\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.2935 - acc: 0.9688\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 315us/step - loss: 0.2902 - acc: 0.9688\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 254us/step - loss: 0.2871 - acc: 0.9688\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 251us/step - loss: 0.2839 - acc: 0.9688\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 327us/step - loss: 0.2808 - acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 215us/step - loss: 0.2777 - acc: 0.9688\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 221us/step - loss: 0.2747 - acc: 0.9688\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 265us/step - loss: 0.2717 - acc: 0.9688\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.2687 - acc: 0.9688\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 355us/step - loss: 0.2658 - acc: 0.9688\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 238us/step - loss: 0.2628 - acc: 0.9688\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 281us/step - loss: 0.2600 - acc: 0.9688\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 320us/step - loss: 0.2572 - acc: 0.9688\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.2543 - acc: 0.9688\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2515 - acc: 0.9688\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 231us/step - loss: 0.2487 - acc: 0.9688\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 364us/step - loss: 0.2460 - acc: 0.9688\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2434 - acc: 0.9688\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 220us/step - loss: 0.2407 - acc: 0.9688\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 366us/step - loss: 0.2381 - acc: 0.9688\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 258us/step - loss: 0.2354 - acc: 0.9688\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 279us/step - loss: 0.2329 - acc: 0.9688\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 235us/step - loss: 0.2303 - acc: 0.9688\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2278 - acc: 0.9688\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.2252 - acc: 0.9688\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.2228 - acc: 0.9688\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 251us/step - loss: 0.2203 - acc: 0.9688\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 403us/step - loss: 0.2179 - acc: 0.9688\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.2155 - acc: 0.9688\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 203us/step - loss: 0.2131 - acc: 0.9688\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 227us/step - loss: 0.2108 - acc: 0.9688\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.2085 - acc: 0.9688\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 354us/step - loss: 0.2062 - acc: 0.9688\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 377us/step - loss: 0.2039 - acc: 0.9688\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.2017 - acc: 0.9688\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 347us/step - loss: 0.1994 - acc: 0.9688\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 0.1973 - acc: 0.9688\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.1951 - acc: 0.9688\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 243us/step - loss: 0.1930 - acc: 0.9688\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 457us/step - loss: 0.1908 - acc: 0.9688\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 208us/step - loss: 0.1887 - acc: 0.9688\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1866 - acc: 0.9688\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 226us/step - loss: 0.1846 - acc: 0.9688\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 286us/step - loss: 0.1825 - acc: 0.9688\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 264us/step - loss: 0.1805 - acc: 0.9688\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 267us/step - loss: 0.1785 - acc: 0.9688\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 263us/step - loss: 0.1765 - acc: 0.9688\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1746 - acc: 0.9688\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 0.1727 - acc: 0.9688\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.1708 - acc: 0.9688\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.1689 - acc: 0.9688\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.1670 - acc: 0.9688\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 0.1651 - acc: 0.9688\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.1633 - acc: 0.9688\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.1615 - acc: 0.9688\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1597 - acc: 0.9688\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.1579 - acc: 0.9688\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.1562 - acc: 0.9688\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.1544 - acc: 0.9688\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1527 - acc: 0.9688\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1509 - acc: 0.9688\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 445us/step - loss: 0.1492 - acc: 0.9688\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 281us/step - loss: 0.1476 - acc: 0.9688\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 520us/step - loss: 0.1459 - acc: 0.9688\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 342us/step - loss: 0.1442 - acc: 0.9688\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 360us/step - loss: 0.1426 - acc: 0.9688\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 334us/step - loss: 0.1410 - acc: 0.9688\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 228us/step - loss: 0.1394 - acc: 0.9688\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 391us/step - loss: 0.1378 - acc: 0.9688\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 310us/step - loss: 0.1362 - acc: 0.9688\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1346 - acc: 0.9688\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 348us/step - loss: 0.1331 - acc: 0.9688\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 216us/step - loss: 0.1316 - acc: 0.9688\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 276us/step - loss: 0.1301 - acc: 0.9688\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 389us/step - loss: 0.1286 - acc: 0.9688\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.1271 - acc: 0.9688\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1256 - acc: 0.9688\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.1242 - acc: 0.9688\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1228 - acc: 0.9688\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 279us/step - loss: 0.1213 - acc: 0.9688\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.1200 - acc: 0.9688\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 209us/step - loss: 0.1186 - acc: 0.9688\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 253us/step - loss: 0.1172 - acc: 0.9688\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 0.1158 - acc: 0.9688\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 61us/step - loss: 0.1145 - acc: 0.9688\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.1132 - acc: 0.9688\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 35us/step - loss: 0.1118 - acc: 0.9688\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.1105 - acc: 0.9688\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.1092 - acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.1079 - acc: 0.9688\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.1067 - acc: 0.9688\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 264us/step - loss: 0.1054 - acc: 0.9688\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 0.1042 - acc: 0.9688\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1029 - acc: 0.9688\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 445us/step - loss: 0.1017 - acc: 0.9688\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1005 - acc: 0.9688\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0993 - acc: 0.9688\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 55us/step - loss: 0.0981 - acc: 0.9688\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0969 - acc: 0.9688\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0957 - acc: 0.9688\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0946 - acc: 0.9688\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.0935 - acc: 0.9688\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0923 - acc: 0.9688\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 61us/step - loss: 0.0912 - acc: 0.9688\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0901 - acc: 0.9688\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.0890 - acc: 0.9688\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0879 - acc: 0.9688\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0868 - acc: 0.9688\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0858 - acc: 0.9688\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 327us/step - loss: 0.0847 - acc: 0.9688\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 228us/step - loss: 0.0837 - acc: 0.9688\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 540us/step - loss: 0.0826 - acc: 0.9688\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 636us/step - loss: 0.0816 - acc: 0.9688\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 199us/step - loss: 0.0806 - acc: 0.9688\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 0.0796 - acc: 0.9688\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0786 - acc: 0.9688\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0777 - acc: 0.9688\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 0.0767 - acc: 0.9688\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 0.0757 - acc: 0.9688\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 0.0748 - acc: 0.9688\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 59us/step - loss: 0.0738 - acc: 0.9688\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0729 - acc: 0.9688\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0720 - acc: 0.9688\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 67us/step - loss: 0.0711 - acc: 0.9688\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.0702 - acc: 0.9688\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 0.0693 - acc: 0.9688\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0684 - acc: 0.9688\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0675 - acc: 0.9688\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0667 - acc: 0.9688\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 0.0658 - acc: 0.9688\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 0.0650 - acc: 0.9688\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 0.0641 - acc: 0.9688\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0633 - acc: 0.9688\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 0.0625 - acc: 0.9688\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0616 - acc: 0.9688\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 0.0608 - acc: 0.9688\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 339us/step - loss: 0.0577 - acc: 1.0000\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 251us/step - loss: 0.0562 - acc: 1.0000\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 316us/step - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0547 - acc: 1.0000\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0540 - acc: 1.0000\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0525 - acc: 1.0000\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 0.0498 - acc: 1.0000\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 40us/step - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 0.0477 - acc: 1.0000\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 47us/step - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 48us/step - loss: 0.0464 - acc: 1.0000\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 61us/step - loss: 0.0457 - acc: 1.0000\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 414us/step - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 348us/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 270us/step - loss: 0.0409 - acc: 1.0000\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 305us/step - loss: 0.0403 - acc: 1.0000\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 225us/step - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 200us/step - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 265us/step - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 308us/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 327us/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 318us/step - loss: 0.0359 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 301us/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 242us/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 49us/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.0319 - acc: 1.0000\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 31us/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 275us/step - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 295us/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 295us/step - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 438us/step - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 241us/step - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 227us/step - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 325us/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 248us/step - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 241us/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 51us/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 55us/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 208us/step - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 71us/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 58us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 198us/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 226us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0105 - acc: 1.0000\n",
      "32/32 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "Smodel=train_2nd_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def predict(image_path_original,image_path_check,FRmodel,Smodel):\n",
    "    encoding_original = img_to_encoding(image_path_original,FRmodel)\n",
    "    encoding_check = img_to_encoding(image_path_check,FRmodel)\n",
    "    dat=encoding_original-encoding_check\n",
    "    \n",
    "    prediction = Smodel.predict_on_batch(dat)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_2_models(image_path_original,image_path_check):\n",
    "    show_images(image_path_original,image_path_check)\n",
    "    print(\"Scoring...............................\")\n",
    "    prediction = predict(image_path_original, image_path_check, FRmodel,Smodel)\n",
    "    score = np.argmax(prediction)\n",
    "    print(\"Score of similarity is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance is  0.002083257306367159\n",
      "It's similar\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring...............................\n",
      "Score of similarity is  2\n"
     ]
    }
   ],
   "source": [
    "verify_ml_approach(\"images/image2.png\", \"images/image1_modified.png\")\n",
    "predict_2_models(\"images/image2.png\", \"images/image1_modified.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance is  0.0012875533429905772\n",
      "It's similar\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring...............................\n",
      "Score of similarity is  8\n"
     ]
    }
   ],
   "source": [
    "verify_ml_approach(\"images/image1.png\", \"images/image1_modified1.png\")\n",
    "predict_2_models(\"images/image1.png\", \"images/image1_modified1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance is  0.0\n",
      "It's similar\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring...............................\n",
      "Score of similarity is  10\n"
     ]
    }
   ],
   "source": [
    "verify_ml_approach(\"images/image3.png\", \"images/image3.png\")\n",
    "predict_2_models(\"images/image3.png\", \"images/image3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance is  0.0020267933141440153\n",
      "It's similar\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring...............................\n",
      "Score of similarity is  10\n"
     ]
    }
   ],
   "source": [
    "verify_ml_approach(\"images/image5.png\", \"images/image6.png\")\n",
    "predict_2_models(\"images/image5.png\", \"images/image6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
